---
layout: post
title: Blog Post 6
---

In this post, we're going to create a neural network that can distinguish between fake and real news, based on the title of the news article and its text using the `tensorflow` library. We also examine the embedding layer we use to visualize relationships between words in our dataset.

## Acquire Training Data

We first import several libraries and download the dataset, which comprises of 22449 observations of news article titles and text, and a categorical variable, `fake`, indicating whether or not the article is fake (0 if the article is not fake, 1 if the article is fake).

```python
import pandas as pd
from nltk.corpus import stopwords
import nltk 
nltk.download('stopwords')
import tensorflow as tf
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
import re
import string
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import losses
import numpy as np

train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
df = pd.read_csv(train_url)
```

## Make a Dataset

We now write a function `make_dataset()` that creates a `tensorflow` `Dataset` without stopwords in `title` and `text`. After removing stopwords, the function outputs a `Dataset` with two inputs, `title` and `text`, and one output, `fake`.

```python
def make_dataset(df):
    # English stopwords
    stop = stopwords.words("english")

    # remove stopwords from title
    df["title"] = df["title"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

    # remove stopwords from text
    df["text"] = df["text"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

    # create Dataset from modified title and text
    my_data_set = tf.data.Dataset.from_tensor_slices(
        (
            {
                "title" : df[["title"]], 
                "text" : df[["text"]]
            }, 
            {
                "fake" : df[["fake"]]
            }
        )
    )

    # set batch to 100 for faster runtime 
    my_data_set.batch(100)
    return my_data_set

data = make_dataset(df)
```

We also split off 20% of the dataset as validation data and 70% as training data.

```python
# shuffle the data to ensure randomness
data = data.shuffle(buffer_size = len(data))

# size of training data
train_size = int(0.7*len(data))

# size of validation data
val_size = int(0.2*len(data))

# create training dataset
train = data.take(train_size)

# create validation dataset
val = data.skip(train_size).take(val_size)

# create testing dataset
test = data.skip(train_size + val_size)

# length of training data for base rate
len(train)
```
15714

We now calculate the base rate, the accuracy of our model if it keeps on making the same guess, which is the majority class.

```python
# create an iterator
fake_iterator= train.unbatch().map(lambda x, fake: fake).as_numpy_iterator()
count = 0

# for each fake in train
for i in range(15714):

  # adds 1 if article is fake and 0 if article is real
  count = count + fake_iterator.next()["fake"]
print(count)
```

8223

Since there are 15714 observations in our training dataset, our base rate is 52.33%. 

## Create Models

We now create three different models, the first using only `title` as the input, the second using only `text` as the input, and the last using both `title` and `text` as the inputs. 

We first create a text preprocessing layer to preprocess our text.

```python
# size of our dataset vocabulary
size_vocabulary = 2000

def standardization(input_data):
    # set all letters to lowercase
    lowercase = tf.strings.lower(input_data)

    # remove punctuation
    no_punctuation = tf.strings.regex_replace(lowercase,
                                  '[%s]' % re.escape(string.punctuation),'')
    return no_punctuation 

vectorize_layer = TextVectorization(
    standardize = standardization,
    max_tokens = size_vocabulary,
    output_mode = 'int',

    # length of output vectors
    output_sequence_length = 500) 

vectorize_layer.adapt(train.map(lambda x, y: x["title"]))
vectorize_layer.adapt(train.map(lambda x, y: x["text"]))
```

The first model only uses `title`.

```python
title_input = keras.Input(
    # shape of title tensors
    shape = (1, ),

    name = "title",
    dtype = "string"
)

# vectorize title input
title_features = vectorize_layer(title_input)

# add an embedding layer to form relationships between words
title_features = layers.Embedding(size_vocabulary, 3, name = "embedding")(title_features)

title_features = layers.Dropout(0.2)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.Dense(32, activation = "relu")(title_features)

# output has two classes
output = layers.Dense(2, name = "fake")(title_features)

# create model
model = keras.Model(
    inputs = title_input,
    outputs = output
)

# use adam optimizier and SparseCategoricalCrossentropy loss function, with accuracy as a metric
model.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)

# train on 50 epochs
history = model.fit(train, 
                    validation_data=val,
                    epochs = 50)

# plot training and validation accuracy across epochs
from matplotlib import pyplot as plt
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
```

/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning:

Input dict contained keys ['text'] which did not match any model input. They will be ignored by the model.

Epoch 1/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.3826 - accuracy: 0.8058 - val_loss: 0.1484 - val_accuracy: 0.9459

Epoch 2/50 15714/15714 [==============================] - 92s 6ms/step - loss: 0.1660 - accuracy: 0.9355 - val_loss: 0.1120 - val_accuracy: 0.9588

Epoch 3/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.1462 - accuracy: 0.9446 - val_loss: 0.0905 - val_accuracy: 0.9679

Epoch 4/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.1284 - accuracy: 0.9500 - val_loss: 0.0879 - val_accuracy: 0.9693

Epoch 5/50 15714/15714 [==============================] - 92s 6ms/step - loss: 0.1229 - accuracy: 0.9512 - val_loss: 0.1193 - val_accuracy: 0.9563

Epoch 6/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.1216 - accuracy: 0.9525 - val_loss: 0.0731 - val_accuracy: 0.9748

Epoch 7/50 15714/15714 [==============================] - 92s 6ms/step - loss: 0.1173 - accuracy: 0.9541 - val_loss: 0.0702 - val_accuracy: 0.9746

Epoch 8/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.1126 - accuracy: 0.9555 - val_loss: 0.0742 - val_accuracy: 0.9724

Epoch 9/50 15714/15714 [==============================] - 92s 6ms/step - loss: 0.1113 - accuracy: 0.9563 - val_loss: 0.0786 - val_accuracy: 0.9735

Epoch 10/50 15714/15714 [==============================] - 92s 6ms/step - loss: 0.1104 - accuracy: 0.9562 - val_loss: 0.0857 - val_accuracy: 0.9657

Epoch 11/50 15714/15714 [==============================] - 92s 6ms/step - loss: 0.1085 - accuracy: 0.9565 - val_loss: 0.0696 - val_accuracy: 0.9746

Epoch 12/50 15714/15714 [==============================] - 91s 6ms/step - loss: 0.1073 - accuracy: 0.9583 - val_loss: 0.0867 - val_accuracy: 0.9681

Epoch 13/50 15714/15714 [==============================] - 91s 6ms/step - loss: 0.1068 - accuracy: 0.9594 - val_loss: 0.0815 - val_accuracy: 0.9670

Epoch 14/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.1020 - accuracy: 0.9611 - val_loss: 0.0735 - val_accuracy: 0.9728

Epoch 15/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.1044 - accuracy: 0.9607 - val_loss: 0.0744 - val_accuracy: 0.9730

Epoch 16/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0997 - accuracy: 0.9624 - val_loss: 0.0651 - val_accuracy: 0.9753

Epoch 17/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.1057 - accuracy: 0.9577 - val_loss: 0.0647 - val_accuracy: 0.9755

Epoch 18/50 15714/15714 [==============================] - 86s 5ms/step - loss: 0.1012 - accuracy: 0.9603 - val_loss: 0.0599 - val_accuracy: 0.9784

Epoch 19/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.1012 - accuracy: 0.9609 - val_loss: 0.0645 - val_accuracy: 0.9777

Epoch 20/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0981 - accuracy: 0.9604 - val_loss: 0.0662 - val_accuracy: 0.9777

Epoch 21/50 15714/15714 [==============================] - 86s 5ms/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.0792 - val_accuracy: 0.9677

Epoch 22/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0994 - accuracy: 0.9619 - val_loss: 0.0758 - val_accuracy: 0.9710

Epoch 23/50 15714/15714 [==============================] - 90s 6ms/step - loss: 0.0974 - accuracy: 0.9617 - val_loss: 0.0614 - val_accuracy: 0.9791

Epoch 24/50 15714/15714 [==============================] - 88s 6ms/step - loss: 0.0982 - accuracy: 0.9620 - val_loss: 0.0576 - val_accuracy: 0.9802

Epoch 25/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0997 - accuracy: 0.9614 - val_loss: 0.1023 - val_accuracy: 0.9588

Epoch 26/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0988 - accuracy: 0.9603 - val_loss: 0.0630 - val_accuracy: 0.9784

Epoch 27/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.1002 - accuracy: 0.9598 - val_loss: 0.0792 - val_accuracy: 0.9690

Epoch 28/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0989 - accuracy: 0.9616 - val_loss: 0.0612 - val_accuracy: 0.9768

Epoch 29/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0966 - accuracy: 0.9626 - val_loss: 0.0802 - val_accuracy: 0.9717

Epoch 30/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0939 - accuracy: 0.9646 - val_loss: 0.0674 - val_accuracy: 0.9742

Epoch 31/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0956 - accuracy: 0.9632 - val_loss: 0.0592 - val_accuracy: 0.9766

Epoch 32/50 15714/15714 [==============================] - 87s 6ms/step - loss: 0.0972 - accuracy: 0.9631 - val_loss: 0.0571 - val_accuracy: 0.9784

Epoch 33/50 15714/15714 [==============================] - 86s 6ms/step - loss: 0.0971 - accuracy: 0.9609 - val_loss: 0.0623 - val_accuracy: 0.9782

Epoch 34/50 15714/15714 [==============================] - 86s 5ms/step - loss: 0.0954 - accuracy: 0.9639 - val_loss: 0.0968 - val_accuracy: 0.9632

Epoch 35/50 15714/15714 [==============================] - 86s 5ms/step - loss: 0.0930 - accuracy: 0.9635 - val_loss: 0.0713 - val_accuracy: 0.9719

Epoch 36/50 15714/15714 [==============================] - 91s 6ms/step - loss: 0.0959 - accuracy: 0.9616 - val_loss: 0.0830 - val_accuracy: 0.9701

Epoch 37/50 15714/15714 [==============================] - 92s 6ms/step - loss: 0.0938 - accuracy: 0.9625 - val_loss: 0.0691 - val_accuracy: 0.9759

Epoch 38/50 15714/15714 [==============================] - 94s 6ms/step - loss: 0.0957 - accuracy: 0.9633 - val_loss: 0.0641 - val_accuracy: 0.9771

Epoch 39/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.0940 - accuracy: 0.9637 - val_loss: 0.0617 - val_accuracy: 0.9782

Epoch 40/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.0910 - accuracy: 0.9646 - val_loss: 0.0615 - val_accuracy: 0.9779

Epoch 41/50 15714/15714 [==============================] - 94s 6ms/step - loss: 0.0945 - accuracy: 0.9637 - val_loss: 0.0592 - val_accuracy: 0.9788

Epoch 42/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.0941 - accuracy: 0.9624 - val_loss: 0.0607 - val_accuracy: 0.9793

Epoch 43/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.0934 - accuracy: 0.9628 - val_loss: 0.0629 - val_accuracy: 0.9751

Epoch 44/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.0880 - accuracy: 0.9673 - val_loss: 0.0672 - val_accuracy: 0.9739

Epoch 45/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.0906 - accuracy: 0.9642 - val_loss: 0.0651 - val_accuracy: 0.9759

Epoch 46/50 15714/15714 [==============================] - 93s 6ms/step - loss: 0.0902 - accuracy: 0.9630 - val_loss: 0.0613 - val_accuracy: 0.9764

Epoch 47/50 15714/15714 [==============================] - 94s 6ms/step - loss: 0.0911 - accuracy: 0.9646 - val_loss: 0.0803 - val_accuracy: 0.9690

Epoch 48/50 15714/15714 [==============================] - 94s 6ms/step - loss: 0.0913 - accuracy: 0.9638 - val_loss: 0.0630 - val_accuracy: 0.9782

Epoch 49/50 15714/15714 [==============================] - 94s 6ms/step - loss: 0.0896 - accuracy: 0.9663 - val_loss: 0.0610 - val_accuracy: 0.9788

Epoch 50/50 15714/15714 [==============================] - 102s 6ms/step - loss: 0.0888 - accuracy: 0.9656 - val_loss: 0.0793 - val_accuracy: 0.9693
[<matplotlib.lines.Line2D at 0x7fd23fa17b90>]

![plot-6-1.png]({{ site.baseurl }}/assets/images/plot-6-1.png)

The second model only uses `text`.

```python
text_input = keras.Input(
    # shape of text tensors
    shape = (1, ),

    name = "title",
    dtype = "string"
)

# vectorize text input
text_features = vectorize_layer(text_input)

# add an embedding layer to form relationships between words
text_features = layers.Embedding(size_vocabulary, 3, name = "embedding")(text_features)

text_features = layers.Dropout(0.2)(text_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.Dense(32, activation = "relu")(text_features)

# output has two classes
output = layers.Dense(2, name = "fake")(text_features)

# create model
model = keras.Model(
    inputs = text_input,
    outputs = output
)

# use adam optimizier and SparseCategoricalCrossentropy loss function, with accuracy as a metric
model.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)

# train on 50 epochs
history = model.fit(train, 
                    validation_data=val,
                    epochs = 50)

# plot training and validation accuracy across epochs
from matplotlib import pyplot as plt
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
```

Epoch 1/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0915 - accuracy: 0.9692 - val_loss: 0.0586 - val_accuracy: 0.9808

Epoch 2/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.0547 - val_accuracy: 0.9855

Epoch 3/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0787 - accuracy: 0.9727 - val_loss: 0.0601 - val_accuracy: 0.9782

Epoch 4/50 15714/15714 [==============================] - 95s 6ms/step - loss: 0.0800 - accuracy: 0.9729 - val_loss: 0.0723 - val_accuracy: 0.9659

Epoch 5/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0765 - accuracy: 0.9723 - val_loss: 0.0430 - val_accuracy: 0.9911

Epoch 6/50 15714/15714 [==============================] - 96s 6ms/step - loss: 0.0719 - accuracy: 0.9749 - val_loss: 0.0468 - val_accuracy: 0.9857

Epoch 7/50 15714/15714 [==============================] - 94s 6ms/step - loss: 0.0719 - accuracy: 0.9747 - val_loss: 0.0417 - val_accuracy: 0.9898

Epoch 8/50 15714/15714 [==============================] - 95s 6ms/step - loss: 0.0731 - accuracy: 0.9750 - val_loss: 0.0643 - val_accuracy: 0.9795

Epoch 9/50 15714/15714 [==============================] - 95s 6ms/step - loss: 0.0665 - accuracy: 0.9771 - val_loss: 0.0509 - val_accuracy: 0.9873

Epoch 10/50 15714/15714 [==============================] - 95s 6ms/step - loss: 0.0729 - accuracy: 0.9745 - val_loss: 0.0573 - val_accuracy: 0.9822

Epoch 11/50 15714/15714 [==============================] - 96s 6ms/step - loss: 0.0674 - accuracy: 0.9756 - val_loss: 0.0443 - val_accuracy: 0.9884

Epoch 12/50 15714/15714 [==============================] - 96s 6ms/step - loss: 0.0699 - accuracy: 0.9750 - val_loss: 0.0413 - val_accuracy: 0.9895

Epoch 13/50 15714/15714 [==============================] - 99s 6ms/step - loss: 0.0664 - accuracy: 0.9760 - val_loss: 0.0396 - val_accuracy: 0.9906

Epoch 14/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0669 - accuracy: 0.9762 - val_loss: 0.0336 - val_accuracy: 0.9926

Epoch 15/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0632 - accuracy: 0.9779 - val_loss: 0.0370 - val_accuracy: 0.9909

Epoch 16/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0633 - accuracy: 0.9784 - val_loss: 0.0381 - val_accuracy: 0.9893

Epoch 17/50 15714/15714 [==============================] - 96s 6ms/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 0.0370 - val_accuracy: 0.9895

Epoch 18/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0600 - accuracy: 0.9797 - val_loss: 0.0422 - val_accuracy: 0.9895

Epoch 19/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0617 - accuracy: 0.9789 - val_loss: 0.0289 - val_accuracy: 0.9909

Epoch 20/50 15714/15714 [==============================] - 99s 6ms/step - loss: 0.0611 - accuracy: 0.9766 - val_loss: 0.0435 - val_accuracy: 0.9898

Epoch 21/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0562 - accuracy: 0.9807 - val_loss: 0.0352 - val_accuracy: 0.9891

Epoch 22/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0618 - accuracy: 0.9784 - val_loss: 0.0322 - val_accuracy: 0.9918

Epoch 23/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0604 - accuracy: 0.9786 - val_loss: 0.0359 - val_accuracy: 0.9898

Epoch 24/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0609 - accuracy: 0.9788 - val_loss: 0.0300 - val_accuracy: 0.9922

Epoch 25/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.0453 - val_accuracy: 0.9889

Epoch 26/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0627 - accuracy: 0.9773 - val_loss: 0.0361 - val_accuracy: 0.9911

Epoch 27/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0565 - accuracy: 0.9794 - val_loss: 0.0372 - val_accuracy: 0.9900

Epoch 28/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0587 - accuracy: 0.9789 - val_loss: 0.0489 - val_accuracy: 0.9822

Epoch 29/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0566 - accuracy: 0.9798 - val_loss: 0.0961 - val_accuracy: 0.9592

Epoch 30/50 15714/15714 [==============================] - 102s 6ms/step - loss: 0.0598 - accuracy: 0.9793 - val_loss: 0.0376 - val_accuracy: 0.9900

Epoch 31/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0553 - accuracy: 0.9800 - val_loss: 0.0401 - val_accuracy: 0.9880

Epoch 32/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0557 - accuracy: 0.9802 - val_loss: 0.0394 - val_accuracy: 0.9909

Epoch 33/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0616 - accuracy: 0.9786 - val_loss: 0.0334 - val_accuracy: 0.9915

Epoch 34/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0574 - accuracy: 0.9815 - val_loss: 0.0421 - val_accuracy: 0.9902

Epoch 35/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0557 - accuracy: 0.9797 - val_loss: 0.0334 - val_accuracy: 0.9906

Epoch 36/50 15714/15714 [==============================] - 100s 6ms/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 0.0306 - val_accuracy: 0.9926

Epoch 37/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 0.0378 - val_accuracy: 0.9882

Epoch 38/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.0254 - val_accuracy: 0.9931

Epoch 39/50 15714/15714 [==============================] - 99s 6ms/step - loss: 0.0572 - accuracy: 0.9806 - val_loss: 0.0380 - val_accuracy: 0.9918

Epoch 40/50 15714/15714 [==============================] - 98s 6ms/step - loss: 0.0558 - accuracy: 0.9797 - val_loss: 0.0364 - val_accuracy: 0.9918

Epoch 41/50 15714/15714 [==============================] - 98s 6ms/step - loss: 0.0560 - accuracy: 0.9815 - val_loss: 0.0359 - val_accuracy: 0.9904

Epoch 42/50 15714/15714 [==============================] - 98s 6ms/step - loss: 0.0552 - accuracy: 0.9817 - val_loss: 0.0368 - val_accuracy: 0.9904

Epoch 43/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0557 - accuracy: 0.9814 - val_loss: 0.0317 - val_accuracy: 0.9935

Epoch 44/50 15714/15714 [==============================] - 96s 6ms/step - loss: 0.0580 - accuracy: 0.9803 - val_loss: 0.0366 - val_accuracy: 0.9893

Epoch 45/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0552 - accuracy: 0.9817 - val_loss: 0.0289 - val_accuracy: 0.9924

Epoch 46/50 15714/15714 [==============================] - 96s 6ms/step - loss: 0.0547 - accuracy: 0.9826 - val_loss: 0.0294 - val_accuracy: 0.9922

Epoch 47/50 15714/15714 [==============================] - 98s 6ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.0427 - val_accuracy: 0.9900

Epoch 48/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.0295 - val_accuracy: 0.9922

Epoch 49/50 15714/15714 [==============================] - 101s 6ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.0368 - val_accuracy: 0.9920

Epoch 50/50 15714/15714 [==============================] - 97s 6ms/step - loss: 0.0515 - accuracy: 0.9819 - val_loss: 0.0285 - val_accuracy: 0.9924
[<matplotlib.lines.Line2D at 0x7f6cc041edd0>]

![plot-6-2.png]({{ site.baseurl }}/assets/images/plot-6-2.png)

The third model uses both `title` and `text`.

```python

# vectorize title and text input
title_features = vectorize_layer(title_input)
text_features = vectorize_layer(text_input)

# shared embedding layer for both title and text
shared_embedding = layers.Embedding(size_vocabulary, 3, name = "embedding")
title_features = shared_embedding(title_features)
text_features = shared_embedding(text_features)

title_features = layers.Dropout(0.2)(title_features)
text_features = layers.Dropout(0.2)(text_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
title_features = layers.Dropout(0.2)(title_features)
text_features = layers.Dropout(0.2)(text_features)
title_features = layers.Dense(32, activation='relu')(title_features)
text_features = layers.Dense(32, activation='relu')(text_features)

# concatenate title features and text features
main = layers.concatenate([title_features, text_features], axis = 1)
main = layers.Dense(32, activation='relu')(main)

# output has two classes
output = layers.Dense(2, name = "fake")(main)

# create model
model = keras.Model(
    inputs = [title_input, text_input],
    outputs = output
)

# use adam optimizier and SparseCategoricalCrossentropy loss function, with accuracy as a metric
model.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)

# train on 50 epochs
history = model.fit(train, 
                    validation_data=val,
                    epochs = 50)

# plot training and validation accuracy across epochs
from matplotlib import pyplot as plt
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
```

Epoch 1/50 15714/15714 [==============================] - 143s 9ms/step - loss: 0.2041 - accuracy: 0.9111 - val_loss: 0.0883 - val_accuracy: 0.9724

Epoch 2/50 15714/15714 [==============================] - 140s 9ms/step - loss: 0.1078 - accuracy: 0.9616 - val_loss: 0.0643 - val_accuracy: 0.9828

Epoch 3/50 15714/15714 [==============================] - 138s 9ms/step - loss: 0.0919 - accuracy: 0.9672 - val_loss: 0.1388 - val_accuracy: 0.9412

Epoch 4/50 15714/15714 [==============================] - 138s 9ms/step - loss: 0.0880 - accuracy: 0.9696 - val_loss: 0.0611 - val_accuracy: 0.9724

Epoch 5/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0768 - accuracy: 0.9734 - val_loss: 0.0660 - val_accuracy: 0.9782

Epoch 6/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0712 - accuracy: 0.9749 - val_loss: 0.0601 - val_accuracy: 0.9715

Epoch 7/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0695 - accuracy: 0.9760 - val_loss: 0.0372 - val_accuracy: 0.9898

Epoch 8/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0664 - accuracy: 0.9765 - val_loss: 0.0550 - val_accuracy: 0.9826

Epoch 9/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0646 - accuracy: 0.9777 - val_loss: 0.0463 - val_accuracy: 0.9864

Epoch 10/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0640 - accuracy: 0.9772 - val_loss: 0.0358 - val_accuracy: 0.9904

Epoch 11/50 15714/15714 [==============================] - 138s 9ms/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 0.0294 - val_accuracy: 0.9920

Epoch 12/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0575 - accuracy: 0.9804 - val_loss: 0.0601 - val_accuracy: 0.9717

Epoch 13/50 15714/15714 [==============================] - 138s 9ms/step - loss: 0.0597 - accuracy: 0.9784 - val_loss: 0.0257 - val_accuracy: 0.9947

Epoch 14/50 15714/15714 [==============================] - 139s 9ms/step - loss: 0.0556 - accuracy: 0.9795 - val_loss: 0.0207 - val_accuracy: 0.9958

Epoch 15/50 15714/15714 [==============================] - 139s 9ms/step - loss: 0.0494 - accuracy: 0.9822 - val_loss: 0.0240 - val_accuracy: 0.9931

Epoch 16/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0546 - accuracy: 0.9812 - val_loss: 0.0354 - val_accuracy: 0.9900

Epoch 17/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 0.0318 - val_accuracy: 0.9924

Epoch 18/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0497 - accuracy: 0.9828 - val_loss: 0.0233 - val_accuracy: 0.9944

Epoch 19/50 15714/15714 [==============================] - 138s 9ms/step - loss: 0.0521 - accuracy: 0.9821 - val_loss: 0.0221 - val_accuracy: 0.9960

Epoch 20/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0471 - accuracy: 0.9847 - val_loss: 0.0265 - val_accuracy: 0.9947

Epoch 21/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0486 - accuracy: 0.9828 - val_loss: 0.0977 - val_accuracy: 0.9579

Epoch 22/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0477 - accuracy: 0.9835 - val_loss: 0.0148 - val_accuracy: 0.9967

Epoch 23/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.0145 - val_accuracy: 0.9967

Epoch 24/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 0.0184 - val_accuracy: 0.9953

Epoch 25/50 15714/15714 [==============================] - 135s 9ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.0201 - val_accuracy: 0.9933

Epoch 26/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.0181 - val_accuracy: 0.9953

Epoch 27/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0139 - val_accuracy: 0.9960

Epoch 28/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 0.0191 - val_accuracy: 0.9962

Epoch 29/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.0199 - val_accuracy: 0.9931

Epoch 30/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0721 - val_accuracy: 0.9722

Epoch 31/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0364 - accuracy: 0.9877 - val_loss: 0.0357 - val_accuracy: 0.9886

Epoch 32/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 0.0180 - val_accuracy: 0.9964

Epoch 33/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0133 - val_accuracy: 0.9955

Epoch 34/50 15714/15714 [==============================] - 135s 9ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.0189 - val_accuracy: 0.9958

Epoch 35/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0330 - accuracy: 0.9901 - val_loss: 0.0385 - val_accuracy: 0.9877

Epoch 36/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0323 - accuracy: 0.9898 - val_loss: 0.0136 - val_accuracy: 0.9967

Epoch 37/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0335 - accuracy: 0.9886 - val_loss: 0.0121 - val_accuracy: 0.9960

Epoch 38/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 0.0074 - val_accuracy: 0.9975

Epoch 39/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0333 - accuracy: 0.9888 - val_loss: 0.0110 - val_accuracy: 0.9973

Epoch 40/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.0162 - val_accuracy: 0.9960

Epoch 41/50 15714/15714 [==============================] - 135s 9ms/step - loss: 0.0315 - accuracy: 0.9892 - val_loss: 0.0135 - val_accuracy: 0.9953

Epoch 42/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0160 - val_accuracy: 0.9980

Epoch 43/50 15714/15714 [==============================] - 135s 9ms/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 0.0124 - val_accuracy: 0.9969

Epoch 44/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0076 - val_accuracy: 0.9980

Epoch 45/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.0105 - val_accuracy: 0.9969

Epoch 46/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.0162 - val_accuracy: 0.9951

Epoch 47/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 0.0084 - val_accuracy: 0.9984

Epoch 48/50 15714/15714 [==============================] - 137s 9ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.0142 - val_accuracy: 0.9975

Epoch 49/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0442 - val_accuracy: 0.9853

Epoch 50/50 15714/15714 [==============================] - 136s 9ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.0104 - val_accuracy: 0.9967
[<matplotlib.lines.Line2D at 0x7fd2c0036e50>]

![plot-6-3.png]({{ site.baseurl }}/assets/images/plot-6-3.png)

While all three models were successful, it seems as if our model that uses both `title` and `text` is most successful. Algorithms should use both `title` and `text` when seeking to detect fake news.

## Model Evaluation

Now we test our best model on test data.

```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
test_df = pd.read_csv(test_url)
test_data = make_dataset(test_df)

# evaluate third model on test dataset
model.evaluate(test_data)
```

22449/22449 [==============================] - 96s 4ms/step - loss: 0.0563 - accuracy: 0.9861
[0.05631158500909805, 0.9861018061637878]

Our model has 98.61% accuracy on the test data, so we didn't overfit. We would detect fake news 98.61% of the time.

## Embedding Visualization

Now we examine our embedding layer more. We create a visualization in `plotly` and examine words that are related to each other to see if they make sense.

```python

# get weights from embedding layer
weights = model.get_layer('embedding').get_weights()[0]
vocab = vectorize_layer.get_vocabulary()

# use PCA with 2 components
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
weights = pca.fit_transform(weights)

embedding_df = pd.DataFrame({
    'word' : vocab, 
    'x0'   : weights[:,0],
    'x1'   : weights[:,1]
})

import plotly.express as px 

# visualize words on a 2d graph
fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1", 
                 size = list(np.ones(len(embedding_df))),
                 size_max = 2,
                 hover_name = "word")

fig.show()
```

{% include embedding.html %}

We can see that `insurance`, `sell`, `financial`, `living`, and `abortion` are close to each other, near the center of our graph. This makes sense, since these topics could be related to women being able to afford abortions with insurance.